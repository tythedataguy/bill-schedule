{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scraper completed! 'bills.csv' saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "import unicodedata\n",
    "\n",
    "base_url = \"https://capitol.texas.gov\"\n",
    "urls = {\n",
    "    \"House\": f\"{base_url}/Committees/MeetingsUpcoming.aspx?Chamber=H\",\n",
    "    \"Senate\": f\"{base_url}/Committees/MeetingsUpcoming.aspx?Chamber=S\",\n",
    "}\n",
    "\n",
    "# Function to clean text\n",
    "def normalize_text(text):\n",
    "    return unicodedata.normalize('NFKD', text).encode('ASCII', 'ignore').decode('utf-8')\n",
    "\n",
    "# Function to extract weekday\n",
    "def extract_weekday(date_text):\n",
    "    try:\n",
    "        match = re.search(r\"([A-Za-z]+ \\d{1,2}, \\d{4})\", date_text)\n",
    "        if match:\n",
    "            return datetime.strptime(match.group(1), \"%B %d, %Y\").strftime(\"%A\")\n",
    "    except ValueError:\n",
    "        pass\n",
    "    return \"Unknown\"\n",
    "\n",
    "# Scrape data\n",
    "data = []\n",
    "for chamber, url in urls.items():\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    meeting_links = [base_url + a[\"href\"] for a in soup.find_all(\"a\", href=True) if a[\"href\"].endswith(\".HTM\")]\n",
    "\n",
    "    for link in meeting_links:\n",
    "        meeting_response = requests.get(link)\n",
    "        meeting_soup = BeautifulSoup(meeting_response.text, \"html.parser\")\n",
    "\n",
    "        committee_name = next((p.text.split(\":\")[-1].strip() for p in meeting_soup.find_all(\"p\") if \"COMMITTEE:\" in p.text), \"Unknown Committee\")\n",
    "        committee_name = re.sub(r\"\\s+\", \" \", committee_name).strip()  # Clean extra spaces\n",
    "\n",
    "        meeting_day = next((extract_weekday(p.text) for p in meeting_soup.find_all(\"p\") if \"TIME & DATE:\" in p.text), \"Unknown\")\n",
    "\n",
    "        for td in meeting_soup.find_all(\"td\"):\n",
    "            bill_link = td.find(\"a\")\n",
    "            if bill_link and \"Bill=\" in bill_link[\"href\"]:\n",
    "                bill_number = bill_link.text.strip()\n",
    "                full_text = td.get_text(\"\\n\").strip()\n",
    "                text_parts = list(filter(None, full_text.split(\"\\n\")))\n",
    "\n",
    "                # Extract Bill Author Properly\n",
    "                bill_author = text_parts[1].strip() if len(text_parts) > 1 else \"Unknown\"\n",
    "                if len(text_parts) > 2 and not text_parts[2].startswith(\"Relating to\"):\n",
    "                    bill_author += \" \" + text_parts[2].strip()\n",
    "                bill_author = re.sub(r\"\\s+\", \" \", bill_author).strip()  # Clean spaces\n",
    "\n",
    "                # Extract Caption Correctly\n",
    "                caption_start = 2 if bill_author != \"Unknown\" else 1\n",
    "                caption = \" \".join(text_parts[caption_start:]).strip()\n",
    "                \n",
    "                # Fix Captions That Contain Author’s Name\n",
    "                if bill_author in caption:\n",
    "                    caption = caption.replace(bill_author, \"\").strip()\n",
    "\n",
    "                # Remove extra spaces and artifacts\n",
    "                caption = re.sub(r\"\\s+\", \" \", caption)  # Removes excessive spaces\n",
    "                caption = caption.replace(\"\\xa0\", \" \").strip()  # Removes `¬†` artifacts\n",
    "\n",
    "                # Ensure Captions Start with \"Relating to\" ONLY when necessary\n",
    "                if not caption.startswith(\"Relating to\") and \"Relating to\" not in caption[:20]:\n",
    "                    caption = \"Relating to \" + caption\n",
    "\n",
    "                # Fix Captions That Start with \"Relating to Relating to\"\n",
    "                caption = caption.replace(\"Relating to Relating to\", \"Relating to\")\n",
    "\n",
    "                # Append Cleaned Data\n",
    "                data.append([chamber, meeting_day, committee_name, bill_number, bill_author, caption])\n",
    "\n",
    "# Convert to DataFrame and Save\n",
    "df = pd.DataFrame(data, columns=[\"Chamber\", \"Day\", \"Committee Name\", \"Bill Number\", \"Bill Author\", \"Caption\"])\n",
    "df[\"Stance\"] = \"\"\n",
    "df.to_csv(\"bills.csv\", index=False)\n",
    "\n",
    "print(\"✅ Scraper completed! 'bills.csv' saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for td in meeting_soup.find_all(\"td\"):\n",
    "    bill_link = td.find(\"a\")\n",
    "    if bill_link and \"Bill=\" in bill_link[\"href\"]:\n",
    "        bill_number = bill_link.text.strip()\n",
    "        full_text = td.get_text(\"\\n\").strip()\n",
    "        text_parts = list(filter(None, full_text.split(\"\\n\")))\n",
    "\n",
    "        # Extract Bill Author correctly\n",
    "        bill_author = text_parts[1].strip() if len(text_parts) > 1 else \"Unknown\"\n",
    "\n",
    "        # Ensure multi-word names don't get split\n",
    "        if len(text_parts) > 2 and not text_parts[2].startswith(\"Relating to\"):\n",
    "            bill_author += \" \" + text_parts[2].strip()\n",
    "\n",
    "        # Clean special characters & extra spaces\n",
    "        bill_author = bill_author.replace(\"\\r\", \"\").strip()\n",
    "\n",
    "        # Extract Caption correctly\n",
    "        caption_start = 2 if bill_author != \"Unknown\" else 1\n",
    "        caption = \" \".join(text_parts[caption_start:]).strip()\n",
    "\n",
    "        # Ensure Caption starts with \"Relating to...\"\n",
    "        if not caption.startswith(\"Relating to\"):\n",
    "            caption = \"Relating to \" + caption\n",
    "\n",
    "        # Append data\n",
    "        data.append([chamber, meeting_day, committee_name, bill_number, bill_author, caption])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
